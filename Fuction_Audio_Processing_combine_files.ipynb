{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1TKJBO1bX2CGo6awtPhr6KE2bBMUGlYrs",
      "authorship_tag": "ABX9TyMufyYQOz+RACu8urrxj7l3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tchamna/Bamileke/blob/main/Fuction_Audio_Processing_combine_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOlSn4nqUOV7"
      },
      "outputs": [],
      "source": [
        "# Ru a Pytho Script in Google Colab\n",
        "# # python \"/content/class_audio_processing_for_aglc_alphet_phonetic_langues_africaines_tonal_languages (2).py\"\n",
        "\n",
        "# !python /content/class_audio_processing_for_aglc_alphet_phonetic_langues_africaines_tonal_languages.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install libraries"
      ],
      "metadata": {
        "id": "HRpzmay3Y9dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install natsort\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fafxmHv44066",
        "outputId": "1417c788-3257-4099-c6a9-7fe60eab4844"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydub"
      ],
      "metadata": {
        "id": "Q-liKbl7ZDWk",
        "outputId": "f370671f-9f10-49c0-b22e-aeba9dbef48d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code defines a function named **get_audio** that takes in three parameters: **audio_path**, **ext** and **check_subfolders**. It imports the necessary modules such as os and glob. The function searches for audio files in a directory specified by the **audio_path** parameter and returns two lists; the first list containing the absolute path of the audio files and the second list containing the relative path of the audio files. The function has an optional parameter **ext** that takes a list of audio file extensions to be searched for, and **check_subfolders** is another optional parameter that specifies whether to search for audio files recursively in subfolders or not."
      ],
      "metadata": {
        "id": "kQwuk7icj9WM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# get_audio() Functions"
      ],
      "metadata": {
        "id": "7vT8XH9AVfW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from posix import mkdir\n",
        "audio_path1 = \"/content/drive/MyDrive/Resulam/Mbú'ŋwɑ̀'nì/test_audio/Language1/\"\n",
        "audio_path2 = \"/content/drive/MyDrive/Resulam/Mbú'ŋwɑ̀'nì/test_audio/Language2/\"\n",
        "\n",
        "\n",
        "# mkdir result\n",
        "\n",
        "import os\n",
        "\n",
        "# Define the path where the \"result\" directory should be created\n",
        "result_path = audio_path2 + \"result/\"\n",
        "\n",
        "# Create the \"result\" directory if it doesn't exist\n",
        "if not os.path.exists(result_path):\n",
        "  mkdir(result_path)\n",
        "\n",
        "\n",
        "# G:\\.shortcut-targets-by-id\\1kt35DKTNYSvIP56JDRN5ukyvOBlyXEwi\\Mbú'ŋwɑ̀'nì\\test_audio\\Laguage2"
      ],
      "metadata": {
        "id": "qxWPaOrEj8Jc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "9ec43c29-98d1-4a0d-e023-2f117f743edd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-deda90e95f7d>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Create the \"result\" directory if it doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: \"/content/drive/MyDrive/Resulam/Mbú'ŋwɑ̀'nì/test_audio/Language2/result/\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "from natsort import natsorted\n",
        "\n",
        "directory_path1 = audio_path1 +\"*mp3\"  # Update with the actual directory path and file extension\n",
        "directory_path2 = audio_path2 +\"*mp3\"  # Update with the actual directory path and file extension\n",
        "\n",
        "# Use glob to get the file names in the directory\n",
        "file_names1 = glob.glob(directory_path1)\n",
        "file_names2 = glob.glob(directory_path2)\n",
        "\n",
        "# Sort the file names based on the Windows initial key\n",
        "sorted_file_names1 = natsorted(file_names1, key=lambda x: x.lower())\n",
        "sorted_file_names2 = natsorted(file_names2, key=lambda x: x.lower())\n",
        "\n",
        "# Print the sorted file names\n",
        "for file_name in sorted_file_names1:\n",
        "    print(file_name)\n"
      ],
      "metadata": {
        "id": "IzxTDp_yhXnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AGLC:\n",
        "\n",
        "  # global len_chuck\n",
        "\n",
        "  def __init__(self,audio_path):\n",
        "    self.vow_map = {'à': 'à', 'á': 'á', 'ā': 'ā', 'ǎ': 'ǎ', 'â': 'â', 'è': 'è', 'é': 'é', 'ē': 'ē', 'ě': 'ě', 'ê': 'ê', 'ì': 'ì', 'í': 'í', 'ī': 'ī', 'ǐ': 'ǐ', 'î': 'î', 'ò': 'ò', 'ó': 'ó', 'ō': 'ō', 'ǒ': 'ǒ', 'ô': 'ô', 'ù': 'ù', 'ú': 'ú', 'ū': 'ū', 'ǔ': 'ǔ', 'û': 'û'}\n",
        "    self.audio_path = audio_path\n",
        "    # self.speed = play_speed\n",
        "    # self.input = input\n",
        "  def vowel_mapping(self,s):\n",
        "    output = \"\"\n",
        "    for char in s:\n",
        "        if char in self.vow_map:\n",
        "            output += self.vow_map[char]\n",
        "        else:\n",
        "            output += char\n",
        "    return output\n",
        "\n",
        "\n",
        "  def get_audio_files_dictionary(self,list_of_audio_files_including_extension):\n",
        "\n",
        "    \"\"\"\n",
        "    The function takes a list of audio files including extensions as input: ['a1.mp3','a2.mp3']\n",
        "    It creates:\n",
        "    - a dictionary where the keys are the audio file names without extensions, and the values are\n",
        "    the audio file names including extensions.\n",
        "    - a new dictionary where the keys are combinations of two audio file names separated by a space\n",
        "    and the values are lists of the corresponding audio file names including extensions.\n",
        "    'a1 a2': ['a1.mp3', 'a2.mp3']\n",
        "    The combinations are formed by iterating over the sorted list of audio file names and adding all pairs of\n",
        "    names that come after the current name in the sorted list.\n",
        "    Finally, the function returns the new dictionary.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    import os\n",
        "    list_of_audio_files_including_extension_base = [ os.path.basename(i) for i in list_of_audio_files_including_extension]\n",
        "    audio_files_no_ext = [i.split(\".\")[0] for i in list_of_audio_files_including_extension_base]\n",
        "\n",
        "    audio_files_dict = dict(zip(audio_files_no_ext, list_of_audio_files_including_extension))\n",
        "\n",
        "    new_dict = {}\n",
        "\n",
        "    sorted_list = sorted(list(audio_files_dict))\n",
        "    for i, val in enumerate(sorted_list):\n",
        "      for j in range(i,len(sorted_list)):\n",
        "        val_j = sorted_list[j]\n",
        "        new_dict[f\"{val} {val_j}\"] = [audio_files_dict[val], audio_files_dict[val_j]]\n",
        "    return new_dict\n",
        "\n",
        "\n",
        "\n",
        "  # Define a function to normalize a chunk to a target amplitude.\n",
        "  def match_target_amplitude(self,aChunk, target_dBFS):\n",
        "      ''' Normalize given audio chunk\n",
        "      The code normalizes an audio chunk to a target amplitude level given as `target_dBFS`.\n",
        "      It calculates the change in decibels (dBFS) required to achieve the target amplitude level and applies it to the input audio chunk.'''\n",
        "      change_in_dBFS = target_dBFS - aChunk.dBFS\n",
        "      return aChunk.apply_gain(change_in_dBFS)\n",
        "\n",
        "\n",
        "  def get_audio(self,audio_path, ext = [\"*.mp3\", \"*.wav\", \"*.ogg\", \"*.flac\"],check_subfolders=False):\n",
        "\n",
        "    \"\"\"\n",
        "    The code defines a function named get_audio that takes in three parameters:\n",
        "    audio_path, ext and check_subfolders. It imports the necessary modules such as os and glob.\n",
        "    The function searches for audio files in a directory specified by the audio_path parameter and returns two lists;\n",
        "    the first list containing the absolute path of the audio files and the second list containing the relative path of the audio files.\n",
        "    The function has an optional parameter ext that takes a list of audio file extensions   to be searched for, and check_subfolders\n",
        "    is another optional parameter that specifies whether to search for audio files recursively in subfolders or not.\n",
        "    \"\"\"\n",
        "\n",
        "    import os\n",
        "    import glob\n",
        "\n",
        "    # List of audio file extensions to search for\n",
        "    # AUDIO_EXTENSIONS = ext\n",
        "\n",
        "    # Directory to search for audio files\n",
        "    directory = audio_path  # Replace with the path to your directory\n",
        "\n",
        "    if check_subfolders == False:\n",
        "      # Search for audio files using glob\n",
        "      audio_files = []\n",
        "      for extension in ext:\n",
        "          audio_files.extend(glob.glob(directory + \"*\" + extension, recursive=check_subfolders))\n",
        "    else:\n",
        "\n",
        "      # Search for audio files using glob\n",
        "      audio_files = []\n",
        "      for extension in ext:\n",
        "          audio_files.extend(glob.glob(directory + \"/**/\" + extension, recursive=check_subfolders))\n",
        "\n",
        "    audio_base_names = [os.path.basename(i) for i in audio_files]\n",
        "\n",
        "    return audio_files, audio_base_names\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # define function to play audio given input string and list of audio files\n",
        "  def play_audio(self,input_string_space_separated, list_of_audio_files_including_extension):\n",
        "      # import required module\n",
        "      from pydub import AudioSegment\n",
        "\n",
        "      # create dictionary of audio files and their corresponding inputs\n",
        "      files = self.get_audio_files_dictionary(list_of_audio_files_including_extension)\n",
        "\n",
        "\n",
        "      # if the input is not in the dictionary, try reversing the input and checking again\n",
        "      if input_string_space_separated not in files:\n",
        "\n",
        "\n",
        "          input_string_space_separated = \" \".join(input_string_space_separated.split()[::-1])\n",
        "          # print(\"...........\",files[input_string_space_separated])\n",
        "          invert_dict = {}\n",
        "          invert_dict[input_string_space_separated] = files[input_string_space_separated][::-1]\n",
        "          files.update(invert_dict)\n",
        "\n",
        "      # create a silent audio segment for a 2 second pause between audio files\n",
        "      silence = AudioSegment.silent(duration=2000)\n",
        "\n",
        "      # get the list of audio files corresponding to the input string\n",
        "      audio_files = files.get(input_string_space_separated)\n",
        "      # print(audio_files)\n",
        "\n",
        "      # raise an error if the input string is invalid\n",
        "      if audio_files is None:\n",
        "          raise ValueError(\"Invalid input string value\")\n",
        "\n",
        "      # create an empty audio segment to add the audio files to\n",
        "      combined_audio = AudioSegment.empty()\n",
        "\n",
        "      # loop through the list of audio files and add each one to the combined audio segment\n",
        "      for filename in audio_files:\n",
        "          audio_segment = AudioSegment.from_file(f\"{filename}\")\n",
        "          combined_audio += audio_segment + silence\n",
        "\n",
        "      # return the combined audio segment\n",
        "      return combined_audio\n",
        "\n",
        "\n",
        "  def play_audio_with_various_space_between_chunks(self,song, min_cut_silence_len = 1.5, silence_padding_duration = 2.5):\n",
        "\n",
        "    \"\"\"\n",
        "    The function takes an audio file and an optional silence duration as input and plays the audio with various spaces between each chunk.\n",
        "    The pydub library is used to split the audio file into chunks where there is silence for a specified duration determined by min_cut_silence_len\n",
        "    and then each chunk is padded with silence of duration silence_padding_duration.\n",
        "    For example, if min_cut_silence_len = 1.5, silence_padding_duration = 2.5\n",
        "    The function then normalizes each chunk and exports them as separate audio files in the mp3 format.\n",
        "    Finally, the function returns the entire audio file with the various spaces between each chunk as an AudioSegment object.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Import the AudioSegment class for processing audio and the\n",
        "    # split_on_silence function for separating out silent chunks.\n",
        "    from pydub import AudioSegment\n",
        "    from pydub.silence import split_on_silence\n",
        "    import os\n",
        "\n",
        "\n",
        "    # Load your audio.\n",
        "    # song = AudioSegment.from_mp3(audio_file_path)\n",
        "\n",
        "    # Split track where the silence is 2 seconds or more and get chunks using\n",
        "    # the imported function.\n",
        "    chunks = split_on_silence (\n",
        "        # Use the loaded audio.\n",
        "        song,\n",
        "        # Specify that a silent chunk must be at least 2 seconds or 2000 ms long.\n",
        "        # min_silence_len = 2000,\n",
        "        min_silence_len = int(min_cut_silence_len*1000),\n",
        "        # Consider a chunk silent if it's quieter than -16 dBFS.\n",
        "        # (You may want to adjust this parameter.)\n",
        "        silence_thresh = -50\n",
        "    )\n",
        "    silence_duration = int(silence_padding_duration*1000)\n",
        "\n",
        "    audio_chunk = AudioSegment.silent(duration=1000)\n",
        "    silence_chunk = AudioSegment.silent(duration=silence_duration)\n",
        "    # Process each chunk with your parameters\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        # Create a silence chunk that's 0.5 seconds (or 500 ms) long for padding.\n",
        "\n",
        "        # print(i, len(chunks))\n",
        "        # Add the padding chunk to beginning and end of the entire chunk.\n",
        "\n",
        "        if i < len(chunks)-1:\n",
        "          audio_chunk += chunk + silence_chunk\n",
        "        if i == len(chunks)-1:\n",
        "          audio_chunk += chunk\n",
        "\n",
        "        # Normalize the entire chunk.\n",
        "        normalized_chunk = self.match_target_amplitude(audio_chunk, -20.0)\n",
        "\n",
        "        # Export the audio chunk with new bitrate.\n",
        "        # print(i)\n",
        "        # print(f\"Exporting chunk{i}.mp3.\")\n",
        "\n",
        "        # normalized_chunk.export(\n",
        "        #     # \".//chunk{0}.mp3\".format(i),\n",
        "        #     f\"_part{i}.mp3\",\n",
        "        #     bitrate = \"192k\",\n",
        "        #     format = \"mp3\"\n",
        "        # )\n",
        "    return audio_chunk, len(chunks)\n",
        "\n",
        "\n",
        "  def play_audio_combine(self,input, speed = 2):\n",
        "\n",
        "    audio_files = self.get_audio(self.audio_path, ext = [\"*.mp3\", \"*.wav\", \"*.ogg\", \"*.flac\"])\n",
        "\n",
        "    list_of_audio_files_including_extension = audio_files[0]\n",
        "    # get_audio_files_dictionary(list_of_audio_files_including_extension)\n",
        "\n",
        "    in_ = self.vowel_mapping(input)\n",
        "    audio_result = self.play_audio(in_,list_of_audio_files_including_extension)\n",
        "    audio_result_modified = self.play_audio_with_various_space_between_chunks(audio_result, silence_padding_duration = float(speed))\n",
        "\n",
        "    return audio_result_modified\n",
        "\n",
        "  def main_func(self,audio_path1, audio_path2,result_path):\n",
        "    import os\n",
        "    from pydub import AudioSegment\n",
        "    from natsort import natsorted\n",
        "    from os.path import basename\n",
        "\n",
        "    silent_end = AudioSegment.silent(duration=1000)\n",
        "    silent_begin = AudioSegment.silent(duration=3000)\n",
        "\n",
        "    audio_files_plus_ext1, audio_files1 = self.get_audio(audio_path1, ext = [\"*.mp3\", \"*.wav\", \"*.ogg\", \"*.flac\"],check_subfolders=False)\n",
        "    audio_files_plus_ext2, audio_files2 = self.get_audio(audio_path2, ext = [\"*.mp3\", \"*.wav\", \"*.ogg\", \"*.flac\"],check_subfolders=False)\n",
        "\n",
        "\n",
        "    # Sort the file names alphabtically\n",
        "    sorted_audio_file_names1 = natsorted(audio_files1, key=lambda x: x.lower())\n",
        "    sorted_audio_file_names2 = natsorted(audio_files2, key=lambda x: x.lower())\n",
        "\n",
        "    sorted_audio_file_names_ext1 = natsorted(audio_files_plus_ext1, key=lambda x: x.lower())\n",
        "    sorted_audio_file_names_ext2 = natsorted(audio_files_plus_ext2, key=lambda x: x.lower())\n",
        "\n",
        "    # Using a dictionary to map indices to filenames for faster lookup\n",
        "\n",
        "\n",
        "    file_dict2 = { ''.join(filter(str.isdigit, basename(path))): basename(path) for path in sorted_audio_file_names_ext1 }\n",
        "\n",
        "    # Create the mapping in a more efficient way\n",
        "    mapping_fast = { basename(path1): file_dict2.get(''.join(filter(str.isdigit, basename(path1))), None)\n",
        "                    for path1 in sorted_audio_file_names_ext2 if ''.join(filter(str.isdigit, basename(path1))) in file_dict2 }\n",
        "\n",
        "\n",
        "\n",
        "    audio_path1_ = [audio_path1 + i for i in mapping_fast.values()]\n",
        "\n",
        "    audio_path2_ = [audio_path2+i for i in mapping_fast.keys()]\n",
        "\n",
        "    silent_2s = AudioSegment.silent(duration=2000)\n",
        "\n",
        "    song = silent_2s\n",
        "\n",
        "    padding_duration = 3\n",
        "\n",
        "    for i in range (0,len(audio_path2_)):\n",
        "      # i = 1\n",
        "      song_name = os.path.basename(audio_path1_[i]).split(\"_\")[0] + \"_\" + os.path.basename(audio_path2_[i])\n",
        "      print(song_name)\n",
        "\n",
        "      song_1 = AudioSegment.from_mp3(audio_path1_[i])\n",
        "      song_2 = AudioSegment.from_mp3(audio_path2_[i])\n",
        "\n",
        "      song_out, number_of_chunks = self.play_audio_with_various_space_between_chunks(song_2, min_cut_silence_len = 1.2, silence_padding_duration = padding_duration)\n",
        "\n",
        "      print(\"number_of_chunks:\",number_of_chunks)\n",
        "\n",
        "\n",
        "      if number_of_chunks == 1:\n",
        "\n",
        "        songi = song_1 + silent_begin + song_2  + silent_begin + song_2\n",
        "\n",
        "      else:\n",
        "\n",
        "        songi = song_1 + silent_begin + song_2\n",
        "\n",
        "      songi.export(\n",
        "              # \".//chunk{0}.mp3\".format(i),\n",
        "              result_path+\"/\"+song_name,\n",
        "              bitrate = \"192k\",\n",
        "              format = \"mp3\"\n",
        "          );\n",
        "      songi\n",
        "\n",
        "\n",
        "    audio_files_plus_ext, audio_files = self.get_audio(result_path, ext = [\"*.mp3\", \"*.wav\", \"*.ogg\", \"*.flac\"],check_subfolders=False)\n",
        "\n",
        "    # Sort the file names alphabtically\n",
        "    audio_files = natsorted(audio_files, key=lambda x: x.lower())\n",
        "\n",
        "    audio_files_plus_ext = natsorted(audio_files_plus_ext, key=lambda x: x.lower())\n",
        "\n",
        "\n",
        "    song = silent_begin\n",
        "\n",
        "\n",
        "\n",
        "    for i in range (0,len(audio_files_plus_ext)):\n",
        "      # i = 1\n",
        "      song_name = os.path.basename(audio_files_plus_ext[i])\n",
        "      print(song_name)\n",
        "      # song_name = f\"{audio_path}reworked/pp_\"+song_name\n",
        "\n",
        "      song_i = AudioSegment.from_mp3(audio_files_plus_ext[i])\n",
        "\n",
        "      # song += song_i+silent_end+flip_page_sound+silent_begin\n",
        "\n",
        "      song += song_i\n",
        "\n",
        "    song_name = f\"{result_path}1_CombineAudio.mp3\"\n",
        "\n",
        "    song.export(\n",
        "              # \".//chunk{0}.mp3\".format(i),\n",
        "              song_name,\n",
        "              bitrate = \"192k\",\n",
        "              format = \"mp3\"\n",
        "          );\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uzo9QwsLVOFk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path1 = \"/content/drive/MyDrive/Resulam/Mbú'ŋwɑ̀'nì/test_audio/Language1/\"\n",
        "audio_path2 = \"/content/drive/MyDrive/Resulam/Mbú'ŋwɑ̀'nì/test_audio/Language2/\"\n",
        "\n",
        "result_path = \"/content/drive/MyDrive/Resulam/Mbú'ŋwɑ̀'nì/test_audio/res/\"\n",
        "\n",
        "\n",
        "player = AGLC(audio_path1)\n",
        "# player_yoruba = AGLC(audio_path_yoruba)\n"
      ],
      "metadata": {
        "id": "_NaC2r-tMdaY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "player.main_func(audio_path1, audio_path2,result_path)"
      ],
      "metadata": {
        "id": "I2M5tdyy5eQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51cc5f24-f1e6-423c-d28e-0b69062e30a6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english_nufi_sentence_1.mp3\n",
            "number_of_chunks: 4\n",
            "english_nufi_sentence_3.mp3\n",
            "number_of_chunks: 1\n",
            "english_nufi_sentence_4.mp3\n",
            "number_of_chunks: 1\n",
            "english_nufi_sentence_5.mp3\n",
            "number_of_chunks: 1\n",
            "english_nufi_sentence_6.mp3\n",
            "number_of_chunks: 1\n",
            "english_nufi_sentence_1.mp3\n",
            "english_nufi_sentence_3.mp3\n",
            "english_nufi_sentence_4.mp3\n",
            "english_nufi_sentence_5.mp3\n",
            "english_nufi_sentence_6.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AudioSegment.from_mp3(audio_files_plus_ext[0])"
      ],
      "metadata": {
        "id": "7ycEE-vE-z0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def normalize_audio_for_ACX_Amazon(song):\n",
        "\n",
        "  desired_sample_rate = 44100  # Replace this with your desired sample rate\n",
        "  song = song.set_frame_rate(desired_sample_rate)\n",
        "\n",
        "\n",
        "  desired_dBFS = -20   # Target volume level in dBFS\n",
        "  current_dBFS = song.dBFS\n",
        "  gain_needed = desired_dBFS - current_dBFS\n",
        "\n",
        "  song_with_desired_volume = song.apply_gain(gain_needed)\n",
        "  # song_with_desired_volume.export(\"/content/output.mp3\", format=\"mp3\", bitrate=\"192000\")\n",
        "\n",
        "\n",
        "  return song_with_desired_volume\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xMOQqaan6IWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GhXHA_KxibNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JtPUxlbxHVV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1NcVh4SO60ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ojSu5CYwM9Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijtOc1qC_rm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQ56pvIeGtbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b936fd-a60b-4d2a-c756-028712685ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english_nufi_sentence_1.mp3\n",
            "english_nufi_sentence_3.mp3\n",
            "english_nufi_sentence_4.mp3\n",
            "english_nufi_sentence_5.mp3\n",
            "english_nufi_sentence_6.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YwJlpF0jM_Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Interface With Gradio"
      ],
      "metadata": {
        "id": "j_O2b61y5o0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio\n"
      ],
      "metadata": {
        "id": "J76xUM3c5sta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fkRl0Lj2NTE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "\n",
        "iface = gr.Interface(fn=main_func,\n",
        "                     inputs=[gr.Textbox(label=\"words: Example: ǎ bà\"),\n",
        "                             gr.Textbox(value=1, label=\"Duration in seconds\"),\n",
        "                             gr.Textbox(label=\"Path\")],\n",
        "                     outputs=\"audio\",\n",
        "                     title=\"AGLC\")\n",
        "\n",
        "iface.launch(share=True,debug=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "dkcK1dws5r7v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "d9d8c880-1fd8-4910-eb1f-42583c07a728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-780f8e4b7216>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m iface = gr.Interface(fn=main_func,\n\u001b[0m\u001b[1;32m      6\u001b[0m                      inputs=[gr.Textbox(label=\"words: Example: ǎ bà\"),\n\u001b[1;32m      7\u001b[0m                              \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Duration in seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'main_func' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b0JBgrYEUPbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7kAZRi7cUPox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install transformers"
      ],
      "metadata": {
        "id": "Oz9qaBrDUPvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "demo = gr.Blocks()\n",
        "\n",
        "with demo:\n",
        "    input_func1 = gr.Audio(type=\"filepath\")\n",
        "    output_func1 = gr.Textbox()\n",
        "    output_func2 = gr.Label()\n",
        "\n",
        "    b1 = gr.Button(\"Recognize Speech\")\n",
        "    b2 = gr.Button(\"Classify Sentiment\")\n",
        "\n",
        "    b1.click(Func1, inputs=input_func1, outputs=output_func1)\n",
        "    b2.click(Func2, inputs=output_func1, outputs=output_func2)\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "2TVjrkRKUP69",
        "outputId": "941b4777-67dd-4e14-c094-5886a8bd9d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-6cca52b8c621>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mButton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classify Sentiment\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_func1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_func1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_func1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_func2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Func1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get_audio(audio_path, ext = [\"*.mp3\", \"*.wav\", \"*.ogg\", \"*.flac\"],check_subfolders=False):\n",
        "# return audio_files, audio_base_names\n",
        "\n",
        "# def get_audio_files_dictionary(list_of_audio_files_including_extension):\n",
        "# return new_dict\n",
        "\n",
        "# play_audio(input_string_space_separated, list_of_audio_files_including_extension):\n",
        "# return combined_audio\n",
        "\n",
        "# play_audio_with_various_space_between_chunks(song, silence_duration = .5):\n",
        "#     return audio_chunk\n",
        "\n",
        "#  list_of_audio_files_including_extension =  get_audio()[0]\n",
        "\n",
        "\n",
        "# audio_result = play_audio(\"bǎ bá\",list_of_audio_files_including_extension)\n",
        "# audio_result_modified = play_audio_with_various_space_between_chunks(audio_result, silence_duration = .2)\n",
        "\n",
        "# gr.Textbox(value=1, label=\"Duration in seconds\"),\n",
        "\n",
        "#  inputs=[gr.Textbox(label=\"words: Example: ǎ bà\"),\n",
        "#                              gr.Textbox(value=1, label=\"Duration in seconds\"),\n",
        "#                              gr.Textbox(label=\"Path\")],\n",
        "\n",
        "def func1(x):\n",
        "  x = float(x)\n",
        "  return x**2\n",
        "\n",
        "def func2(y):\n",
        "  y = float(y)\n",
        "  return y**2\n",
        "\n",
        "def func3(a):\n",
        "  a = float(a)\n",
        "  # b = float(b)\n",
        "  return 2*a\n",
        "\n",
        "\n",
        "\n",
        "demo = gr.Blocks()\n",
        "\n",
        "with demo:\n",
        "    input_func1 = gr.Textbox(label = \"val1\")\n",
        "    input_func2 = gr.Textbox(label = \"val2\")\n",
        "    # input_func3 = [gr.Textbox(label = \"val3\")\n",
        "\n",
        "    output_func1 = gr.Label(label = \"result1\")\n",
        "    output_func2 = gr.Label(label = \"result2\")\n",
        "    output_func3 = gr.Label(label = \"result3\")\n",
        "\n",
        "    b1 = gr.Button(\"x^2\")\n",
        "    b2 = gr.Button(\"y^2\")\n",
        "    b3 = gr.Button(\"x^2+y^2\")\n",
        "\n",
        "\n",
        "    b1.click(func1, inputs=input_func1, outputs=output_func1)\n",
        "    b2.click(func2, inputs=input_func2, outputs=output_func2)\n",
        "    b3.click(func3, inputs=output_func1, outputs=output_func3)\n",
        "\n",
        "    # b2.click(play_audio, inputs=output_func1, outputs=output_func2)\n",
        "\n",
        "demo.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "id": "fZQutZRuWg-n",
        "outputId": "a28493c9-4997-4f46-b1ae-d56e5b8394e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://81b7cac44f6bc3c875.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://81b7cac44f6bc3c875.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/routes.py\", line 414, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1323, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1051, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-121-13f4df176f66>\", line 34, in func3\n",
            "    a = float(a)\n",
            "TypeError: float() argument must be a string or a real number, not 'dict'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7870 <> https://81b7cac44f6bc3c875.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main_func(input_string, speed = 1):\n",
        "  audio_result = play_audio(input_string)\n",
        "\n",
        "  audio_result_modified = play_audio_with_various_space_between_chunks(audio_result, silence_duration = float(speed))\n",
        "  return audio_result_modified\n",
        "\n",
        "main_func(\"ǎ bà\",\".1\")"
      ],
      "metadata": {
        "id": "6dQfoMlo8uPD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}